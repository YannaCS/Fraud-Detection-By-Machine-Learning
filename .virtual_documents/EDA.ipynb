


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('seaborn-v0_8-deep') 
# other tyle: ggplot, Solarize_Light2





# Load the dataset
df = pd.read_csv('./data/applications data.csv',sep=',')

print("DATASET OVERVIEW")
print("-" * 40)
print(f"Dataset shape: {df.shape}")
print(f"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB")
print(f"\nColumn names: {df.columns.tolist()}")
print("\nDataset info:\n")
display(df.info())


# Check for Personally Identifiable Information (PII) data and create anonymized version if needed
pii_columns = ['ssn', 'firstname', 'lastname', 'address', 'dob', 'homephone']
print(f"PII columns: {pii_columns}")
print("Random sample records of the dataset excluding the pii columns for privacy protection:")
display(df[[c for c in df.columns.to_list() if c not in pii_columns]].sample(3))





sum((df.record - 1 - df.index) == 0) == len(df)


if 'record' in df.columns:
    df.drop('record', axis=1, inplace=True)
    print('record column has been removed')   
else:
    print('no record column in dataset found')


print("STATISTICAL SUMMARY")
print("-" * 40)

# Basic statistics for numerical features
print("\nFeatures summary:")
display(df.describe().round(3))

# Separate statistics by class
print("\n\nStatistics for NORMAL transactions:")
display(df[df['fraud_label'] == 0].describe().round(3).iloc[:, :])

print("\n\nStatistics for FRAUD transactions:")
display(df[df['fraud_label'] == 1].describe().round(3).iloc[:, :])








print("DATA QUALITY ASSESSMENT")
print("-" * 40)

# Check missing values
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100

print(f"Missing values per column:")
if missing_values.sum() == 0:
    print("No missing values found in the dataset! âœ“")
else:
    missing_df = pd.DataFrame({
        'Column': missing_values[missing_values > 0].index,
        'Missing_Count': missing_values[missing_values > 0].values,
        'Percentage': missing_percentage[missing_values > 0].values
    })
    print(missing_df)

# Check for duplicates
duplicates = df.duplicated().sum()
print(f"\nDuplicate rows: {duplicates} ({duplicates/len(df)*100:.2f}%)")
if duplicates > 0:
    df.drop_duplicates(keep='first', inplace=True)
    if df.duplicated().sum() == 0:
        print('Duplicates based on all columns have been removed, only keep the first record.')
# Check for infinite values
inf_values = np.isinf(df.select_dtypes(include=[np.number])).sum().sum()
print(f"\nInfinite values: {inf_values}")





#original data types
df.dtypes


# change date format
df['date'] = df['date'].apply(pd.to_datetime,format='%Y%m%d')
print(f"Date range: {df['date'].min()} to {df['date'].max()}")
# change other features data type
df.ssn = df.ssn.astype(str)
df.zip5 = df.zip5.astype(str)
df.dob = df.dob.astype(str)
df.homephone = df.homephone.astype(str)


# add leading 0 to zips
df['zip5'] = df.zip5.apply(lambda x: x if len(x) == 5 else '0'*(5-len(x)) + x)








# 2016 was a leap year that should had 366 days
print('number of days in the dataset: ',len(df['date'].unique()))


daily_count = df.assign(apps = np.ones(len(df))).groupby('date')['apps'].count()
daily_count


# using plot to find which day is lost
#by seaborn: sns.lineplot(data = daily_count)
#by pd directly: daily_count.plot(title = 'Daily Applications')
#by matplotlib
fig, ax = plt.subplots(figsize=(8, 5))
ax.plot(daily_count)
ax.set_xlabel('date',fontsize=10)
ax.set_ylabel('count',fontsize=10)
ax.tick_params(axis='x', labelrotation=15)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)
date_format = mdates.DateFormatter('%m-%d')
ax.xaxis.set_major_formatter(date_format)
ax.set_xlim([df.date.min(), df.date.max()])
fig.suptitle('Daily Applications', fontsize=12)
plt.show()





# Resample to weekly (assuming daily_count is a Series with datetime index)
weekly_count = daily_count.resample('W').sum()
weekly_count


fig, ax = plt.subplots(figsize=(8, 5))
ax.plot(weekly_count)

ax.set_xlabel('date', fontsize=10)
ax.set_ylabel('count', fontsize=10)
ax.tick_params(axis='x', labelrotation=15)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

date_format = mdates.DateFormatter('%m-%d')
ax.xaxis.set_major_formatter(date_format)

ax.set_xlim([weekly_count.index.min(), weekly_count.index.max()])

fig.suptitle('Weekly Applications', fontsize=12)
plt.tight_layout()
plt.show()





features_to_check = ['ssn', 'firstname', 'lastname', 'address', 'zip5', 'dob','homephone']
fig, ax = plt.subplots(nrows=4, ncols=2, figsize=(15, 20))
ax = ax.flatten()

for i, c in enumerate(features_to_check):
    df[c].value_counts().head(15).plot(kind='bar', ax=ax[i])
    ax[i].set_yscale('log')
    ax[i].set_xlabel(c, fontsize=10)
    ax[i].set_ylabel('count', fontsize=10)
    ax[i].set_title(f'Top 15 most frequent {c}', fontsize=12)
    ax[i].tick_params(axis='x', labelrotation=30, labelsize=8)
    
    # Set horizontal alignment to 'right'
    for label in ax[i].get_xticklabels():
        label.set_ha('right')

# Hide unused axes
for j in range(len(features_to_check), len(ax)):
    fig.delaxes(ax[j])

plt.tight_layout()
plt.show()


for c in features_to_check:
    print(f'\n{df[c].value_counts()}\n')





len(df.loc[(df.ssn=='999999999') | (df.address == '123 MAIN ST') | (df.dob == 19070626) \
      |(df.homephone == 9999999999)]) / len(df)





df = df.loc[(df.ssn!='999999999') & (df.address != '123 MAIN ST') & (df.dob != 19070626) \
      &(df.homephone != 9999999999)]
len(df)





df.reset_index(drop=True, inplace=True)
df.to_csv('./data/cleaned.csv')





print("TARGET VARIABLE DISTRIBUTION")
print("-" * 40)

fraud_counts = df['fraud_label'].value_counts()
fraud_percentage = df['fraud_label'].value_counts(normalize=True) * 100

print(f"Normal transactions: {fraud_counts[0]:,} ({fraud_percentage[0]:.2f}%)")
print(f"Fraudulent transactions: {fraud_counts[1]:,} ({fraud_percentage[1]:.2f}%)")
print(f"Imbalance ratio: 1:{int(fraud_counts[0]/fraud_counts[1])}")
if abs(fraud_percentage[0] - fraud_percentage[1]) > 40:
    print("This dataset is super imbalanced")

# Visualization of class distribution
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3), gridspec_kw={'width_ratios': [1, 2]})
fig.subplots_adjust(wspace=0)
#colors = ['#1DB954', '#F03A17']
#colors = ['#384860', '#a00000']
colors = ['#4C72B0', '#a00000']
# Bar plot
ax1.bar(['Normal', 'Fraud'], fraud_counts.values, color = ['#4C72B0', '#a00000'], width=0.3)
ax1.set_ylabel('Count')
ax1.set_title('Transaction Fraud Distribution')
for i, v in enumerate(fraud_counts.values):
    ax1.text(i, v + 1000, f'{v:,}', ha='center', fontweight='bold', fontsize=8)

# Pie chart
wedges, texts, autotexts = ax2.pie(fraud_counts.values, labels=['Normal', 'Fraud'], 
                                   colors=colors, 
                                   autopct='%1.2f%%', startangle=90)
ax2.set_title('Transaction Fraud Percentage')

plt.tight_layout()
#plt.savefig('class_distribution.png', dpi=300, bbox_inches='tight', facecolor='#191414')
plt.show()


print("TIME ANALYSIS")
print("-" * 40)

# Extract time features

df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['dayofweek'] = df['date'].dt.dayofweek
df['day_name'] = df['date'].dt.day_name()

print(f"Date range: {df['date'].min()} to {df['date'].max()}")
print(f"Time span: {(df['date'].max() - df['date'].min()).days} days")

# Fraud distribution over time
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))

# Day of week distribution
dow_fraud = df.groupby('day_name')['fraud_label'].agg(['sum', 'count', 'mean'])
dow_fraud['fraud_rate'] = dow_fraud['mean'] * 100
dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
dow_fraud = dow_fraud.reindex(dow_order)

ax1.bar(dow_fraud.index, dow_fraud['fraud_rate'], color='#c46666')

# total transaction by day of week
ax1_twin = ax1.twinx()
ax1_twin.plot(dow_fraud.index, dow_fraud['count'], color='#4C72B0')

ax1.set_title('Fraud Rate and Total Number of Transactions by Day of Week')
ax1.set_ylabel('Fraud Rate (%)', color='#a00000')
ax1_twin.set_ylabel('Total Number of Transactions', color='#4C72B0')
ax1.tick_params(axis='x', rotation=45)
ax1.tick_params(axis='y', labelcolor='#a00000')
ax1_twin.tick_params(axis='y', labelcolor='#4C72B0')


# Fraud rate by month
fraud_rate_by_month = df.groupby('month')['fraud_label'].mean() * 100
ax2.plot(fraud_rate_by_month.index, fraud_rate_by_month.values, 
         color='#a00000', linewidth=2, marker='o')
ax2.set_title('Fraud Rate by Month')
ax2.set_xlabel('Month')
ax2.set_ylabel('Fraud Rate (%)')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
#plt.savefig('time_analysis.png', dpi=300, bbox_inches='tight', facecolor='#191414')
plt.show()

# Key findings from time analysis
peak_fraud_month = fraud_rate_by_month.idxmax()
print(f"\nPeak fraud month: {peak_fraud_month} (fraud rate: {fraud_rate_by_month.max():.3f}%)")
print(f"Lowest fraud month: {fraud_rate_by_month.idxmin()} (fraud rate: {fraud_rate_by_month.min():.3f}%)")


# Group by day of week and month to count frauds
options = ['day', 'dayofweek']
fig, ax = plt.subplots(2, 1, figsize=(14, 15))
for i, option in enumerate(options):
    fraud_time = df[df['fraud_label'] == 1].groupby([option, 'month']).size().unstack(fill_value=0)
    if option == 'dayofweek':
        yticklabels=['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
    else:
        yticklabels = list(df.day.unique())
    sns.heatmap(fraud_time, cmap="YlOrRd", annot=True, fmt='d', ax=ax[i],
                yticklabels = yticklabels)
    ax[i].set_title(f"Fraudulent Transactions by {option} and Month")
    ax[i].set_xlabel("Month")
    ax[i].set_ylabel(option)
plt.tight_layout()
plt.show()


print("ZIP CODE ANALYSIS")
print("-" * 40)

# Analyze zip code patterns
zip_fraud_rate = df.groupby('zip5')['fraud_label'].agg(['sum', 'count', 'mean'])
zip_fraud_rate.columns = ['fraud_count', 'total_count', 'fraud_rate']
zip_fraud_rate = zip_fraud_rate.sort_values('fraud_rate', ascending=False)

print("Top 10 ZIP codes by fraud rate (minimum 10 transactions):")
high_fraud_zips = zip_fraud_rate[zip_fraud_rate['total_count'] >= 10].head(10)
print(high_fraud_zips)

# Visualize ZIP code analysis
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# Top fraud ZIP codes color=['#4C72B0', '#a00000']
high_fraud_zips['fraud_rate'].plot(kind='bar', ax=ax1, color='#a00000')
ax1.set_title('Top 10 ZIP Codes by Fraud Rate')
ax1.set_xlabel('ZIP Code')
ax1.set_ylabel('Fraud Rate')
ax1.tick_params(axis='x', rotation=45)

# Transaction volume by ZIP
top_volume_zips = zip_fraud_rate.nlargest(10, 'total_count')
top_volume_zips['total_count'].plot(kind='bar', ax=ax2, color='#4C72B0')
ax2.set_title('Top 10 ZIP Codes by Transaction Volume')
ax2.set_xlabel('ZIP Code')
ax2.set_ylabel('Number of Transactions')
ax2.tick_params(axis='x', rotation=45)

plt.tight_layout()
#plt.savefig('zip_analysis.png', dpi=300, bbox_inches='tight', facecolor='#191414')
plt.show()



